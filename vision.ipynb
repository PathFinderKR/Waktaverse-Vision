{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Importing Libraries",
   "metadata": {
    "collapsed": false
   },
   "id": "f21a95a142b71e93"
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "from PIL import Image\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:12:54.970880Z",
     "start_time": "2024-06-12T10:12:52.684692Z"
    }
   },
   "id": "108874429856aabe",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f29fda50194a3fe"
  },
  {
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:12:55.084660Z",
     "start_time": "2024-06-12T10:12:54.973477Z"
    }
   },
   "id": "5555b5512cd1a1dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T10:12:55.118276Z",
     "start_time": "2024-06-12T10:12:55.086297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flash Attention Implementation\n",
    "if device == \"cuda:0\":\n",
    "    if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "        attn_implementation = \"flash_attention_2\"\n",
    "        torch_dtype = torch.bfloat16\n",
    "    else:\n",
    "        attn_implementation = \"eager\"\n",
    "        torch_dtype = torch.float16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float32\n",
    "print(f\"Attention Implementation = {attn_implementation}\")"
   ],
   "id": "f0e72bfaf9471e1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Implementation = flash_attention_2\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b452e9ab5ed33883"
  },
  {
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "max_length=8192\n",
    "padding=\"do_not_pad\"  # \"max_length\", \"longest\", \"do_not_pad\"\n",
    "truncation=True\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "num_return_sequences=1\n",
    "max_new_tokens=1024\n",
    "do_sample=True  # True for sampling, False for greedy decoding\n",
    "temperature=0.6\n",
    "top_p=0.9\n",
    "repetition_penalty=1.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "load_in_4bit=True\n",
    "bnb_4bit_compute_dtype=torch_dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:12:55.125419Z",
     "start_time": "2024-06-12T10:12:55.120210Z"
    }
   },
   "id": "778930f2cc7c1224",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f31dc8d02b7233"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model ID\n",
    "model_id = \"qresearch/llama-3-vision-alpha-hf\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:12:55.139951Z",
     "start_time": "2024-06-12T10:12:55.128425Z"
    }
   },
   "id": "352852804a6a38db",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T10:12:55.786383Z",
     "start_time": "2024-06-12T10:12:55.142153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_fast=True\n",
    ")"
   ],
   "id": "3a1ea98f6eba58f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T10:12:55.793511Z",
     "start_time": "2024-06-12T10:12:55.788149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
    "    llm_int8_skip_modules=[\"mm_projector\", \"vision_model\"]\n",
    ")"
   ],
   "id": "be26d2efc49fcbf6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    #attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    quantization_config=quantization_config,\n",
    "    trust_remote_code=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:13:10.982215Z",
     "start_time": "2024-06-12T10:12:55.795339Z"
    }
   },
   "id": "f5f879cefa518232",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93940213a93e4a3f9160c200ee38c94d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T10:13:10.988504Z",
     "start_time": "2024-06-12T10:13:10.983349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the model architecture\n",
    "display(Markdown(f'```{model}```'))"
   ],
   "id": "9fedd479c0a753a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```Llamavision(\n  (text_model): LlamaForCausalLM(\n    (model): LlamaModel(\n      (embed_tokens): Embedding(128256, 4096)\n      (layers): ModuleList(\n        (0-31): 32 x LlamaDecoderLayer(\n          (self_attn): LlamaSdpaAttention(\n            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            (rotary_emb): LlamaRotaryEmbedding()\n          )\n          (mlp): LlamaMLP(\n            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n            (act_fn): SiLU()\n          )\n          (input_layernorm): LlamaRMSNorm()\n          (post_attention_layernorm): LlamaRMSNorm()\n        )\n      )\n      (norm): LlamaRMSNorm()\n    )\n    (lm_head): Linear4bit(in_features=4096, out_features=128256, bias=False)\n  )\n  (vision_model): SiglipVisionModel(\n    (vision_model): SiglipVisionTransformer(\n      (embeddings): SiglipVisionEmbeddings(\n        (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n        (position_embedding): Embedding(729, 1152)\n      )\n      (encoder): SiglipEncoder(\n        (layers): ModuleList(\n          (0-26): 27 x SiglipEncoderLayer(\n            (self_attn): SiglipAttention(\n              (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n              (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n              (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n              (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n            )\n            (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n            (mlp): SiglipMLP(\n              (activation_fn): PytorchGELUTanh()\n              (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n              (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n            )\n            (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n          )\n        )\n      )\n      (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n      (head): SiglipMultiheadAttentionPoolingHead(\n        (attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=1152, out_features=1152, bias=True)\n        )\n        (layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): SiglipMLP(\n          (activation_fn): PytorchGELUTanh()\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n        )\n      )\n    )\n  )\n  (mm_projector): ProjectionModule(\n    (model): Sequential(\n      (0): Linear(in_features=1152, out_features=4096, bias=True)\n      (1): GELU(approximate='none')\n      (2): Linear(in_features=4096, out_features=4096, bias=True)\n    )\n  )\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T10:13:11.003958Z",
     "start_time": "2024-06-12T10:13:10.989704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of parameters\n",
    "print(f\"Number of parameters (in billions): {model.num_parameters() / 1e9:.2f}\")"
   ],
   "id": "2ae15c79b7731f1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters (in billions): 8.48\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "12b7e2fc01311961"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T10:13:11.017074Z",
     "start_time": "2024-06-12T10:13:11.005111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# image path\n",
    "image_path = \"images/\""
   ],
   "id": "9d9de5d2b485a6de",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T10:13:11.046461Z",
     "start_time": "2024-06-12T10:13:11.018299Z"
    }
   },
   "cell_type": "code",
   "source": "image = Image.open(image_path + \"output.png\")",
   "id": "22fd7b7cae51bf10",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T10:13:15.401264Z",
     "start_time": "2024-06-12T10:13:11.047742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    tokenizer.decode(\n",
    "        model.answer_question(image, \"question\", tokenizer),\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    ")"
   ],
   "id": "dcf090679065c13f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A majestic lion in the night sky!\n",
      "\n",
      "This stunning image features a lion in mid-leap, its mane flowing in the wind as it bounds across the rocky terrain. The full moon shines brightly above, casting a silver glow over the entire scene. The lion's eyes glow like embers, adding a touch of mystique to the already breathtaking image.\n",
      "\n",
      "What do you think of this regal creature in the night sky?\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
